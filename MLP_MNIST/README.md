# Рекуррентная нейронная сеть LSTM

Этот проект представляет собой реализацию многослойного персептрона (MLP) для классификации рукописных цифр из набора данных MNIST. Проект оформлен в виде Jupyter Notebook — `MLP_MNIST.ipynb`, в котором показаны этапы создания, обучения и оценки модели MLP для задачи классификации изображений.

## Содержание
- [Технологии](#технологии)
- [Установка](#установка)
- [Описание модели](#описание-модели)
- [Пример использования](#пример-использования)
- [Результаты](#результаты)

## Технологии

Проект использует следующие технологии и библиотеки:

- **Python**
- **NumPy**
- **TensorFlow/Keras** — для создания и обучения LSTM-модели
- **Matplotlib** — для визуализации результатов

## Установка

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/lepy0ha/NN/MLP_MNIST.git
   ```
2. Установите необходимые зависимости:
   ```bash
   pip install -r requirements.txt
   ```
## Описание модели
Модель MLP используется для классификации изображений с цифрами (0–9) из набора данных MNIST. Основные этапы работы включают в себя:

- **Подготовка данных**: загрузка, нормализация и подготовка данных MNIST для ввода в нейронную сеть.
- **Модели обучения**: модели обучения MLP для обучающего набора данных.
- **Оценочные модели**: проверка точности предсказаний на основе набора данных.
## Архитектура модели
Модель построена на основе нескольких полносвязных слоев с пониженной эффективностью ReLU, завершающим выходным слоем для класса предсказания.

## Пример использования
В файле `MLP_MNIST.ipynb` представлен пример, включающий следующие шаги:

1. Загрузка и подготовка данных.
2. Обучение MLP-модели.
3. Модели точности оценки и визуализация предсказаний.

Пример инициализации и обучения модели можно увидеть в ноутбуке, а также выполнить следующие команды:

```python
# Инициализация и обучение модели
for epoch in range(num_epochs):
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
```